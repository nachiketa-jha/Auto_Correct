{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "w=[]\n",
    "\n",
    "with open('final.txt', 'r', encoding='utf8') as f:\n",
    "    file_name = f.read()\n",
    "    file_name = file_name.lower()\n",
    "    w = re.findall('\\w+', file_name)\n",
    "\n",
    "main_set = set(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counting_words(words):\n",
    "    word_count = {}\n",
    "    for word in words:\n",
    "        if word in word_count:\n",
    "            word_count[word]+=1\n",
    "        else:\n",
    "            word_count[word] =1\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_cal(word_count_dict):\n",
    "    probs = {}\n",
    "    m = sum(word_count_dict.values())\n",
    "    for key in word_count_dict.keys():\n",
    "        probs[key] = word_count_dict[key] / m\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization\n",
    "Deletion of letter\n",
    "Switching Letter\n",
    "Replace Letter\n",
    "Insert new Letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import lexeme\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def LemmWord(word):\n",
    "    return list(lexeme(wd) for wd in word.split())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_letter(word):\n",
    "    delete_list = []\n",
    "    split_list =[]\n",
    "    for i in range(len(word)):\n",
    "        split_list.append((word[0:i], word[i:]))\n",
    "\n",
    "    for a,b in split_list:\n",
    "        delete_list.append(a +b[1:])\n",
    "    \n",
    "    return delete_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch(word):\n",
    "    split_list = []\n",
    "    switch_list = []\n",
    "    for i in range(len(word)):\n",
    "        split_list.append((word[0:i], word[i:0]))\n",
    "    \n",
    "    switch_list = [a + b[1] + b[0] + b[2:] for a, b in split_list if len(b)>=2]\n",
    "    return switch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(word):\n",
    "    split_list = []\n",
    "    replace_list = []\n",
    "    for i in range(len(word)):\n",
    "        split_list.append((word[0:i], word[i:]))\n",
    "\n",
    "    alphs = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    replace_list = [a + c + b[1:] if len(b) > c else '' for a, b in split_list if b for c in alphs]\n",
    "\n",
    "    return replace_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert(word):\n",
    "    split_list = []\n",
    "    insert_list = []\n",
    "    for i in range(len(word)):\n",
    "        split_list.append((word[0:i], word[i:]))\n",
    "\n",
    "    alphs = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    insert_list = [a + c + b for a, b in split_list for c in alphs]\n",
    "    return insert_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colab_1(word, allow_switches=True):\n",
    "    colab_1 = set()\n",
    "    colab_1.update(delete_letter(word))\n",
    "    if allow_switches:\n",
    "        colab_1.update(switch(word))\n",
    "    colab_1.update(replace(word))\n",
    "    colab_1.update(insert(word))\n",
    "    return colab_1\n",
    "\n",
    "def colab_2(word, allow_switches=True):\n",
    "    colab_2 = set()\n",
    "    edit_one = colab_1(word, allow_switches=allow_switches)\n",
    "    for w in edit_one:\n",
    "        if w:\n",
    "            edit_two = colab_1(w, allow_switches=allow_switches)\n",
    "            colab_2.update(edit_two)\n",
    "    return colab_2\n",
    "\n",
    "\n",
    "# print(colab_1('hello'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only storing those values which are in the vocab\n",
    "def get_corrections(word, probs, vocab, n=2):\n",
    "    suggested_word = []\n",
    "    best_suggestion = []\n",
    "    suggested_word = list(\n",
    "        (word in vocab and word) or colab_1(word).intersection(vocab)\n",
    "        or colab_2(word).intersection(\n",
    "            vocab))\n",
    "\n",
    "    # finding out the words with high frequencies\n",
    "    best_suggestion = [[s, probs[s]] for s in list(reversed(suggested_word))]\n",
    "    return best_suggestion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m probs \u001b[38;5;241m=\u001b[39m probab_cal(word_count)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# only storing correct words\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m tmp_corrections \u001b[38;5;241m=\u001b[39m \u001b[43mget_corrections\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_word\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, word_prob \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tmp_corrections):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m):\n",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m, in \u001b[0;36mget_corrections\u001b[0;34m(word, probs, vocab, n)\u001b[0m\n\u001b[1;32m      3\u001b[0m suggested_word \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m best_suggestion \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m suggested_word \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m----> 6\u001b[0m     (word \u001b[38;5;129;01min\u001b[39;00m vocab \u001b[38;5;129;01mand\u001b[39;00m word) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mcolab_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mintersection(vocab)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m colab_2(word)\u001b[38;5;241m.\u001b[39mintersection(\n\u001b[1;32m      8\u001b[0m         vocab))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# finding out the words with high frequencies\u001b[39;00m\n\u001b[1;32m     11\u001b[0m best_suggestion \u001b[38;5;241m=\u001b[39m [[s, probs[s]] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(suggested_word))]\n",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m, in \u001b[0;36mcolab_1\u001b[0;34m(word, allow_switches)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_switches:\n\u001b[1;32m      5\u001b[0m     colab_1\u001b[38;5;241m.\u001b[39mupdate(switch(word))\n\u001b[0;32m----> 6\u001b[0m colab_1\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      7\u001b[0m colab_1\u001b[38;5;241m.\u001b[39mupdate(insert(word))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m colab_1\n",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m, in \u001b[0;36mreplace\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m      5\u001b[0m     split_list\u001b[38;5;241m.\u001b[39mappend((word[\u001b[38;5;241m0\u001b[39m:i], word[i:]))\n\u001b[1;32m      7\u001b[0m alphs \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabcdefghijklmnopqrstuvwxyz\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 8\u001b[0m replace_list \u001b[38;5;241m=\u001b[39m [a \u001b[38;5;241m+\u001b[39m c \u001b[38;5;241m+\u001b[39m b[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;241m>\u001b[39m c \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m split_list \u001b[38;5;28;01mif\u001b[39;00m b \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m alphs]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m replace_list\n",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m     split_list\u001b[38;5;241m.\u001b[39mappend((word[\u001b[38;5;241m0\u001b[39m:i], word[i:]))\n\u001b[1;32m      7\u001b[0m alphs \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabcdefghijklmnopqrstuvwxyz\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 8\u001b[0m replace_list \u001b[38;5;241m=\u001b[39m [a \u001b[38;5;241m+\u001b[39m c \u001b[38;5;241m+\u001b[39m b[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m split_list \u001b[38;5;28;01mif\u001b[39;00m b \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m alphs]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m replace_list\n",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "my_word = input(\"Enter any word:\")\n",
    "\n",
    "# Counting word function\n",
    "word_count = counting_words(main_set)\n",
    "\n",
    "# Function to calculate word probabilities\n",
    "def probab_cal(word_count):\n",
    "    total_words = sum(word_count.values())\n",
    "    probs = {word: count/total_words for word, count in word_count.items()}\n",
    "    return probs\n",
    "\n",
    "# Calculating probability\n",
    "probs = probab_cal(word_count)\n",
    "\n",
    "# only storing correct words\n",
    "tmp_corrections = get_corrections(my_word, probs, main_set, 2)\n",
    "for i, word_prob in enumerate(tmp_corrections):\n",
    "    if(i < 3):\n",
    "        print(word_prob[0])\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
